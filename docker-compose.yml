services:
  atlas:
    image: sburn/apache-atlas:latest
    container_name: apache-atlas
    ports:
      - "21000:21000"
    environment:
      - JAVA_OPTS=-Xmx1536m -Xms768m
      - ATLAS_SERVER_OPTS=-server -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+CMSClassUnloadingEnabled -XX:+UseConcMarkSweepGC -XX:+CMSPermGenSweepingEnabled
    volumes:
      - atlas_data:/opt/atlas/data
      - atlas_logs:/opt/atlas/logs
    restart: unless-stopped
    mem_limit: 3g
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:21000 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 180s
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    networks:
      - plataform-network

  postgres_erp:
    container_name: postgres-erp
    image: postgres:14.19-alpine3.21
    restart: always
    environment:
      POSTGRES_DB: northwind
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --lc-collate=C --lc-ctype=C"
    volumes:                  
      - postgres_data:/var/lib/postgresql/data
      - ./db:/docker-entrypoint-initdb.d
    ports:
      - 2001:5432
    networks:
      - plataform-network
  pyspark-aula:
    build:
      context: .
      dockerfile: Dockerfile_Spark
    
    container_name: pyspark_aula_container
    user: root
    
    # Mapeia as portas
    ports:
      - "8888:8888" # Porta do Jupyter Notebook
      - "4040:4040" # Porta da UI do Spark (importante para monitorar os jobs!)
      
    # Mapeia o diretório local para o contêiner (Persistência dos arquivos)
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data
      - ./spark_jobs:/home/jovyan/work/spark_jobs
      - ./iceberg_warehouse:/home/jovyan/iceberg-warehouse

    # Variáveis de ambiente
    environment:
      # Token de acesso ao Jupyter (opcional, mas recomendado para segurança)
      - JUPYTER_TOKEN=tavares1234
      # Configurações do Spark (opcional, mas bom para aumentar a memória para testes)
      - SPARK_DRIVER_MEMORY=4g
      - SPARK_EXECUTOR_MEMORY=4g
      
    # Reinicia o contêiner em caso de falha
    restart: always
    networks:
      - plataform-network
  airflow-standalone:
    build:
      context: .
      dockerfile: Dockerfile_AirFlow
    # build: .
    # image: airflow3-custom:latest
    user: root
    ports:
      - "5000:8080"
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@postgres_erp:5432/northwind
      AIRFLOW__WEBSERVER__AUTHENTICATE: 'True'
      AIRFLOW__WEBSERVER__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data:rw
      - ./spark_jobs:/opt/airflow/spark_jobs
      - /var/run/docker.sock:/var/run/docker.sock
    command: >
      bash -c "
      /opt/airflow/init_connections.sh &&
      airflow standalone
      "
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - plataform-network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - plataform-network
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - plataform-network
    restart: unless-stopped

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat
    user: root
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./logs:/var/log/airflow:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: filebeat -e -strict.perms=false
    depends_on:
      - elasticsearch
    networks:
      - plataform-network
    restart: unless-stopped

  metricbeat:
    image: docker.elastic.co/beats/metricbeat:8.11.0
    container_name: metricbeat
    user: root
    volumes:
      - ./metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: metricbeat -e -strict.perms=false
    depends_on:
      - elasticsearch
    networks:
      - plataform-network
    restart: unless-stopped

volumes:
  postgres_data:
  atlas_data:
  atlas_logs:
  iceberg_warehouse:
  elasticsearch_data:

networks:
  plataform-network:
    ipam:
      driver: default
      config:
        - subnet: "172.16.240.0/24"
