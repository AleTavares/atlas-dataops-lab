# Apache Atlas DataOps Lab

> **Laborat√≥rio completo para aprendizado de cataloga√ß√£o de dados com Apache Atlas, PostgreSQL e Python**

## Sobre o Projeto

Este reposit√≥rio fornece um ambiente completo de aprendizado para **Data Governance** e **DataOps** usando Apache Atlas como cat√°logo de dados. O projeto demonstra desde conceitos b√°sicos at√© implementa√ß√µes avan√ßadas de descoberta autom√°tica de metadados, linhagem de dados e integra√ß√£o com bancos relacionais.

### Objetivos de Aprendizado

- **Cataloga√ß√£o de Dados**: Criar e gerenciar cat√°logos de metadados
- **API Integration**: Integrar sistemas via REST APIs do Apache Atlas
- **Data Lineage**: Mapear origem e transforma√ß√µes de dados
- **Metadata Management**: Extrair e organizar metadados estruturais
- **DataOps Practices**: Automatizar descoberta e cataloga√ß√£o

## Arquitetura do Sistema

### Diagrama de Arquitetura

```mermaid
graph TB
    subgraph "Camada de Apresenta√ß√£o"
        UI1["Apache Atlas UI<br/>:21000"]
        UI2["Airflow UI<br/>:5000"]
        UI3["Kibana<br/>:5601"]
        UI4["Jupyter Notebook<br/>:8888"]
    end

    subgraph "Camada de Orquestra√ß√£o"
        AF["Apache Airflow<br/>Scheduler + Webserver"]
        DAG1["catalog_postgres_to_atlas"]
        DAG2["etl_northwind_to_iceberg"]
        DAG3["cleanup_atlas"]
        DAG4["setup_spark_connection"]
        
        AF --> DAG1
        AF --> DAG2
        AF --> DAG3
        AF --> DAG4
    end

    subgraph "Camada de Processamento"
        SPARK["PySpark Engine<br/>Distributed Processing"]
        SPARKUI["Spark UI :4040"]
        JOBS["Spark Jobs<br/>northwind_to_iceberg.py"]
        
        SPARK --> SPARKUI
        SPARK --> JOBS
    end

    subgraph "Camada de Governan√ßa"
        ATLAS["Apache Atlas<br/>Metadata Catalog"]
        HBASE["HBase<br/>Graph Storage"]
        SOLR["Apache Solr<br/>Search Index"]
        KAFKA["Kafka<br/>Event Bus"]
        
        ATLAS --> HBASE
        ATLAS --> SOLR
        ATLAS --> KAFKA
    end

    subgraph "Camada de Dados"
        PG[("PostgreSQL<br/>Northwind DB<br/>:2001")]
        ICEBERG["Apache Iceberg<br/>Data Lake<br/>Raw Layer"]
        WAREHOUSE["Iceberg Warehouse<br/>Versioned Tables"]
        
        ICEBERG --> WAREHOUSE
    end

    subgraph "Camada de Observabilidade"
        ES[("Elasticsearch<br/>Log Storage<br/>:9200")]
        FB["Filebeat<br/>Log Collector"]
        MB["Metricbeat<br/>Metrics Collector"]
        
        FB --> ES
        MB --> ES
        ES --> UI3
    end

    subgraph "Integra√ß√µes"
        API1["Atlas REST API"]
        API2["Airflow REST API"]
        DOCKER["Docker Socket<br/>/var/run/docker.sock"]
    end

    %% Fluxos de Dados
    DAG1 -."Extrai Metadados".-> PG
    DAG1 -."Cataloga".-> ATLAS
    
    DAG2 -."Submete Job".-> SPARK
    SPARK -."L√™ Dados".-> PG
    SPARK -."Escreve".-> ICEBERG
    SPARK -."Registra Linhagem".-> ATLAS
    
    UI4 -."Executa Notebooks".-> SPARK
    UI4 -."Consulta".-> ICEBERG
    
    AF -."Monitora".-> DOCKER
    FB -."Coleta Logs".-> AF
    FB -."Coleta Logs".-> ATLAS
    FB -."Coleta Logs".-> SPARK
    MB -."Coleta M√©tricas".-> DOCKER
    
    UI1 --> ATLAS
    UI2 --> AF
    
    ATLAS --> API1
    AF --> API2

    %% Estilos
    classDef uiClass fill:#e1f5ff,stroke:#01579b,stroke-width:2px
    classDef orchestrationClass fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef processingClass fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef governanceClass fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px
    classDef dataClass fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef monitoringClass fill:#fff9c4,stroke:#f57f17,stroke-width:2px
    
    class UI1,UI2,UI3,UI4 uiClass
    class AF,DAG1,DAG2,DAG3,DAG4 orchestrationClass
    class SPARK,SPARKUI,JOBS processingClass
    class ATLAS,HBASE,SOLR,KAFKA governanceClass
    class PG,ICEBERG,WAREHOUSE dataClass
    class ES,FB,MB monitoringClass
```

### Stack Tecnol√≥gica

| Componente | Tecnologia | Vers√£o | Porta | Fun√ß√£o |
|------------|------------|--------|-------|--------|
| **Cat√°logo** | Apache Atlas | 2.3.0 | 21000 | Governan√ßa e metadados |
| **Database** | PostgreSQL | 14.19 | 2001 | Dados de exemplo (Northwind) |
| **Orquestra√ß√£o** | Apache Airflow | 3.0.0 | 5000 | Workflows e ETL |
| **Analytics** | PySpark + Jupyter | Latest | 8888 | An√°lise e notebooks |
| **Data Lake** | Apache Iceberg | 1.4.3 | - | Armazenamento com versionamento |
| **Monitoring** | Elasticsearch | 8.11.0 | 9200 | Armazenamento de logs |
| **Visualization** | Kibana | 8.11.0 | 5601 | Dashboards e an√°lise |
| **Log Shipping** | Filebeat | 8.11.0 | - | Coleta de logs |
| **Metrics** | Metricbeat | 8.11.0 | - | Coleta de m√©tricas |
| **Storage** | HBase (embedded) | - | - | Persist√™ncia Atlas |
| **Search** | Apache Solr (embedded) | - | - | Indexa√ß√£o e busca |
| **Messaging** | Apache Kafka (embedded) | - | - | Eventos e notifica√ß√µes |

### Fluxos de Dados Principais

#### 1. **Cataloga√ß√£o de Metadados (DAG: catalog_postgres_to_atlas)**
```
PostgreSQL ‚Üí Airflow ‚Üí Extra√ß√£o de Schema ‚Üí Apache Atlas ‚Üí Cat√°logo Centralizado
```
- Extrai estrutura de tabelas, colunas e relacionamentos
- Registra metadados no Atlas via REST API
- Execu√ß√£o di√°ria automatizada

#### 2. **Pipeline ETL com Linhagem (DAG: etl_northwind_to_iceberg)**
```
PostgreSQL ‚Üí Spark Job ‚Üí Transforma√ß√£o ‚Üí Iceberg Tables ‚Üí Atlas (Linhagem)
```
- L√™ dados do Northwind
- Processa com PySpark
- Armazena em formato Iceberg
- Registra linhagem completa no Atlas
- Aplica tags de qualidade automaticamente

#### 3. **Observabilidade e Monitoramento**
```
Containers ‚Üí Filebeat/Metricbeat ‚Üí Elasticsearch ‚Üí Kibana Dashboards
```
- Coleta logs de todos os servi√ßos
- Coleta m√©tricas de containers (CPU, mem√≥ria, rede)
- Visualiza√ß√£o em tempo real
- Alertas configur√°veis

## Estrutura do Reposit√≥rio

```
atlas-dataops-lab/
‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestra√ß√£o dos servi√ßos
‚îú‚îÄ‚îÄ Dockerfile                  # Atlas customizado
‚îú‚îÄ‚îÄ Dockerfile_Spark           # PySpark + Jupyter + Iceberg
‚îú‚îÄ‚îÄ Dockerfile_AirFlow         # Apache Airflow
‚îú‚îÄ‚îÄ wait-for-atlas.sh          # Script de inicializa√ß√£o
‚îú‚îÄ‚îÄ users-credentials.properties # Autentica√ß√£o Atlas
‚îú‚îÄ‚îÄ requirements.txt           # Depend√™ncias globais
‚îú‚îÄ‚îÄ airflow_connections.py     # Configura√ß√£o de conex√µes
‚îú‚îÄ‚îÄ spark_remote_submit.py     # Wrapper Spark remoto
‚îú‚îÄ‚îÄ .env                       # Vari√°veis de ambiente
‚îú‚îÄ‚îÄ LICENSE                    # Licen√ßa do projeto
‚îú‚îÄ‚îÄ README.md                  # Este arquivo
‚îú‚îÄ‚îÄ .gitignore                # Arquivos ignorados
‚îÇ
‚îú‚îÄ‚îÄ dags/                      # DAGs do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ catalog_postgres_to_atlas.py # DAG de cataloga√ß√£o PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ cleanup_atlas.py       # DAG de limpeza do Atlas
‚îÇ   ‚îú‚îÄ‚îÄ etl_northwind_to_iceberg.py # DAG ETL Spark + Iceberg
‚îÇ   ‚îî‚îÄ‚îÄ setup_spark_connection.py # DAG setup conex√£o Spark
‚îÇ
‚îú‚îÄ‚îÄ spark_jobs/                # Jobs Spark
‚îÇ   ‚îî‚îÄ‚îÄ northwind_to_iceberg.py # ETL Northwind -> Iceberg
‚îÇ
‚îú‚îÄ‚îÄ logs/                      # Logs do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ dag_processor/         # Logs de processamento
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep              # Mant√©m diret√≥rio no Git
‚îÇ
‚îú‚îÄ‚îÄ plugins/                   # Plugins customizados do Airflow
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ data/                      # Datasets para an√°lise
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îî‚îÄ‚îÄ northwind.sql          # Schema e dados PostgreSQL
‚îÇ
‚îú‚îÄ‚îÄ Exercicios/
‚îÇ   ‚îî‚îÄ‚îÄ EXERCICIO_ATLAS.md     # Exerc√≠cio pr√°tico completo
‚îÇ
‚îú‚îÄ‚îÄ lab/
‚îÇ   ‚îú‚îÄ‚îÄ atlas_client.py        # Cliente Python para Atlas API
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configura√ß√µes do laborat√≥rio
‚îÇ   ‚îú‚îÄ‚îÄ data_discovery.py      # Descoberta de dados
‚îÇ   ‚îú‚îÄ‚îÄ lineage_demo.py        # Demonstra√ß√£o de linhagem
‚îÇ   ‚îú‚îÄ‚îÄ postgres_integration.py # Integra√ß√£o PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ LAB_ATLAS_PYTHON.md    # Guia do laborat√≥rio Python
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îÇ   ‚îî‚îÄ‚îÄ run_lab.sh            # Script de execu√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ Lab_Catalogo_Postgres_no_Atlas.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ Iceberg_Demo.ipynb     # Demo Apache Iceberg
‚îÇ   ‚îî‚îÄ‚îÄ data/                  # Dados para notebooks
‚îÇ
‚îî‚îÄ‚îÄ respostas/
    ‚îú‚îÄ‚îÄ config_exercicio.py    # Configura√ß√µes do exerc√≠cio
    ‚îú‚îÄ‚îÄ requirements_exercicio.txt # Depend√™ncias do exerc√≠cio
    ‚îî‚îÄ‚îÄ SOLUCAO_EXERCICIO.py   # Solu√ß√£o completa
```

## In√≠cio R√°pido

### 1. Pr√©-requisitos

- **Docker** >= 20.10
- **Docker Compose** >= 2.0
- **Python** >= 3.8 (opcional, para desenvolvimento local)
- **8GB RAM** dispon√≠vel (recomendado)

### 2. Inicializa√ß√£o

```bash
# Clonar o reposit√≥rio
git clone https://github.com/AleTavares/atlas-dataops-lab.git
cd atlas-dataops-lab

# Iniciar todos os servi√ßos
docker-compose up --build -d

# Aguardar inicializa√ß√£o (5-10 minutos)
./wait-for-atlas.sh

# Verificar status dos servi√ßos
docker-compose ps
```

### 3. Acesso aos Servi√ßos

| Servi√ßo | URL | Credenciais |
|---------|-----|-------------|
| **Apache Atlas** | http://localhost:21000 | admin / admin |
| **Apache Airflow** | http://localhost:5000 | admin / admin |
| **Kibana** | http://localhost:5601 | - |
| **Elasticsearch** | http://localhost:9200 | - |
| **Jupyter Notebook** | http://localhost:8888 | Token: tavares1234 |
| **PostgreSQL** | localhost:2001 | postgres / postgres |

## Laborat√≥rios Dispon√≠veis

### Lab 1: Cliente Atlas B√°sico
```bash
cd lab
pip install -r requirements.txt
python atlas_client.py
```
**Aprenda**: Conex√£o com Atlas, busca de entidades, API REST

### Lab 2: Jupyter Notebook Interativo
```bash
# Acessar: http://localhost:8888 (token: tavares1234)
# Abrir: Lab_Catalogo_Postgres_no_Atlas.ipynb
```
**Aprenda**: Extra√ß√£o de metadados, cataloga√ß√£o autom√°tica, visualiza√ß√£o

### Lab 3: Airflow - Cataloga√ß√£o Autom√°tica
```bash
# Acessar: http://localhost:5000 (admin/admin)
# Executar DAG: catalog_postgres_to_atlas
```
**Aprenda**: Orquestra√ß√£o de workflows de cataloga√ß√£o

### Lab 3.1: Airflow - Limpeza do Atlas
```bash
# Acessar: http://localhost:5000 (admin/admin)
# Executar DAG: cleanup_atlas (execu√ß√£o manual)
```
**Aprenda**: Manuten√ß√£o e limpeza de metadados

### Lab 4: Spark + Iceberg - ETL Completo
```bash
# Acessar: http://localhost:5000 (admin/admin)
# Executar DAG: etl_northwind_to_iceberg
```
**Aprenda**: ETL com Spark, Iceberg, linhagem e tags de qualidade

### Lab 5: Iceberg Demo Interativo
```bash
# Acessar: http://localhost:8888 (token: tavares1234)
# Abrir: Iceberg_Demo.ipynb
```
**Aprenda**: Apache Iceberg, time travel, versionamento

### Lab 6: Exerc√≠cio Pr√°tico Completo
```bash
# Seguir instru√ß√µes em EXERCICIO_ATLAS.md
```
**Aprenda**: Implementa√ß√£o completa de catalogador de dados

## Configura√ß√µes Detalhadas

### Apache Atlas
- **Modo**: Standalone com componentes embedded
- **Storage**: BerkeleyDB para grafos, HBase para metadados
- **Search**: Apache Solr embedded
- **Messaging**: Kafka embedded para eventos
- **Autentica√ß√£o**: File-based (users-credentials.properties)
- **Mem√≥ria**: 1.5GB heap, 768MB inicial
- **Persist√™ncia**: Volume Docker `atlas_data`
- **Healthcheck**: Verifica√ß√£o a cada 30s com 180s de startup
- **Limites**: 3GB RAM m√°xima, 65536 file descriptors

### PostgreSQL Northwind
- **Database**: northwind (carregado automaticamente)
- **Tabelas**: 14 tabelas relacionais completas
  - `customers`, `products`, `orders`, `order_details`
  - `employees`, `categories`, `suppliers`, `shippers`
  - `territories`, `region`, `employee_territories`
  - `customer_demographics`, `customer_customer_demo`
- **Dados**: ~3000 registros com relacionamentos
- **Persist√™ncia**: Volume Docker `postgres_data`
- **Encoding**: UTF8 com collation C

### PySpark + Jupyter
- **Base Image**: jupyter/pyspark-notebook:latest
- **Packages**: requests, psycopg2-binary, pandas, matplotlib, seaborn, pyiceberg
- **Volumes**: notebooks/, data/, spark_jobs/ e iceberg_warehouse/ mapeados
- **Spark UI**: http://localhost:4040 (quando jobs est√£o rodando)
- **Mem√≥ria**: 4GB driver, 4GB executor
- **Iceberg**: Suporte completo para Apache Iceberg 1.4.3

### Apache Airflow
- **Modo**: Standalone (scheduler + webserver + executor)
- **Backend**: PostgreSQL (compartilhado com Northwind)
- **Executor**: Local Executor
- **Autentica√ß√£o**: Basic Auth (admin/admin)
- **Volumes**: dags/, logs/, plugins/, spark_jobs/ mapeados
- **Docker Socket**: Acesso para submiss√£o remota de jobs Spark
- **Healthcheck**: Verifica√ß√£o a cada 30s

### Elastic Stack
- **Elasticsearch**: Single-node, sem seguran√ßa, 512MB heap
- **Kibana**: Conectado ao Elasticsearch, dashboards pr√©-configurados
- **Filebeat**: Coleta logs do Airflow e containers Docker
- **Metricbeat**: Coleta m√©tricas de CPU, mem√≥ria, rede e disco dos containers
- **Persist√™ncia**: Volume Docker `elasticsearch_data`

### Rede
- **Nome**: plataform-network
- **Subnet**: 172.16.240.0/24
- **Driver**: Bridge (padr√£o)
- **Comunica√ß√£o**: Todos os containers na mesma rede

## DAGs Dispon√≠veis

### 1. **catalog_postgres_to_atlas**
- **Descri√ß√£o**: Cataloga√ß√£o autom√°tica do PostgreSQL Northwind no Atlas
- **Schedule**: Di√°rio (`@daily`)
- **Tasks**: 
  - `extract_metadata` - Extrai metadados do PostgreSQL
  - `create_database` - Cria database no Atlas
  - `catalog_tables` - Cataloga estrutura das tabelas
  - `catalog_columns` - Cataloga colunas das tabelas
- **Execu√ß√£o**: Autom√°tica ou manual

### 2. **cleanup_atlas**
- **Descri√ß√£o**: Limpeza completa de todas as entidades do Atlas
- **Schedule**: Manual apenas
- **Tasks**:
  - `get_all_entities` - Lista todas as entidades
  - `delete_columns` - Remove todas as colunas
  - `delete_tables` - Remove todas as tabelas
  - `delete_databases` - Remove todos os databases
  - `cleanup_remaining` - Limpa entidades restantes
- **‚ö†Ô∏è ATEN√á√ÉO**: Remove TODAS as entidades do Atlas

### 3. **etl_northwind_to_iceberg**
- **Descri√ß√£o**: ETL completo Northwind PostgreSQL para Iceberg Raw Layer
- **Schedule**: Semanal (`@weekly`)
- **Tasks**:
  - `check_spark_job` - Verifica exist√™ncia do job Spark
  - `submit_spark_job` - Executa job Spark no container pyspark-aula
  - `validate_results` - Valida tabelas criadas via Atlas API
- **Funcionalidades**: Extra√ß√£o, cataloga√ß√£o, linhagem, tags de qualidade

### 4. **setup_spark_connection**
- **Descri√ß√£o**: Configura√ß√£o da conex√£o Spark no Airflow
- **Schedule**: Manual apenas
- **Tasks**:
  - `create_spark_connection` - Cria conex√£o spark_container
- **Uso**: Executar uma vez para configurar ambiente

## Comandos √öteis

### Gerenciamento de Servi√ßos
```bash
# Ver logs espec√≠ficos
docker-compose logs -f atlas
docker-compose logs -f postgres_erp
docker-compose logs -f airflow-standalone
docker-compose logs -f pyspark-aula

# Reiniciar servi√ßo espec√≠fico
docker-compose restart atlas

# Parar todos os servi√ßos
docker-compose down

# Limpar volumes (CUIDADO: perde dados)
docker-compose down -v

# Rebuild completo
docker-compose up --build --force-recreate

# Verificar status de todos os servi√ßos
docker-compose ps

# Verificar sa√∫de dos containers
docker-compose ps --format json | jq '.[] | {name: .Name, status: .Status, health: .Health}'
```

### Airflow - Gerenciamento de DAGs
```bash
# Listar DAGs
docker exec -it airflow-standalone airflow dags list

# Executar DAG manualmente
docker exec -it airflow-standalone airflow dags trigger catalog_postgres_to_atlas
docker exec -it airflow-standalone airflow dags trigger etl_northwind_to_iceberg

# Ver status de execu√ß√£o
docker exec -it airflow-standalone airflow dags state catalog_postgres_to_atlas

# Pausar/Despausar DAG
docker exec -it airflow-standalone airflow dags pause catalog_postgres_to_atlas
docker exec -it airflow-standalone airflow dags unpause catalog_postgres_to_atlas

# Ver logs de uma task espec√≠fica
docker exec -it airflow-standalone airflow tasks logs catalog_postgres_to_atlas extract_metadata 2025-01-01
```

### Spark - Gerenciamento de Jobs
```bash
# Acessar container Spark
docker exec -it pyspark_aula_container bash

# Submeter job Spark manualmente
docker exec -it pyspark_aula_container spark-submit \
  --master local[*] \
  /home/jovyan/work/spark_jobs/northwind_to_iceberg.py

# Ver jobs Spark em execu√ß√£o
curl http://localhost:4040/api/v1/applications

# Listar tabelas Iceberg criadas
docker exec -it pyspark_aula_container ls -la /home/jovyan/iceberg-warehouse/
```

### Atlas - Gerenciamento de Metadados
```bash
# Testar conectividade Atlas
curl -u admin:admin http://localhost:21000/api/atlas/admin/version

# Listar tipos de entidades
curl -u admin:admin http://localhost:21000/api/atlas/v2/types/typedefs

# Buscar entidades por tipo
curl -u admin:admin "http://localhost:21000/api/atlas/v2/search/basic?typeName=rdbms_table"

# Contar entidades
curl -u admin:admin "http://localhost:21000/api/atlas/v2/search/basic?typeName=rdbms_table&limit=0" | jq '.approximateCount'

# Limpar todas as entidades (usar com cuidado!)
./reset-atlas.sh
```

### PostgreSQL - Consultas
```bash
# Testar PostgreSQL
docker exec -it postgres-erp psql -U postgres -d northwind -c "SELECT count(*) FROM customers;"

# Listar todas as tabelas
docker exec -it postgres-erp psql -U postgres -d northwind -c "\dt"

# Acessar console interativo
docker exec -it postgres-erp psql -U postgres -d northwind

# Backup do banco
docker exec -it postgres-erp pg_dump -U postgres northwind > northwind_backup.sql
```

### Monitoring - Elastic Stack
```bash
# Verificar sa√∫de do Elasticsearch
curl http://localhost:9200/_cluster/health?pretty

# Listar √≠ndices
curl http://localhost:9200/_cat/indices?v

# Contar documentos em √≠ndice
curl http://localhost:9200/metricbeat-*/_count

# Testar Filebeat
docker exec filebeat filebeat test config
docker exec filebeat filebeat test output

# Testar Metricbeat
docker exec metricbeat metricbeat test config
docker exec metricbeat metricbeat test output

# Configurar dashboards
./monitoring/setup_dashboards.sh
```

### Diagn√≥stico e Performance
```bash
# Verificar recursos de todos os containers
docker stats

# Verificar uso de disco
df -h
docker system df

# Limpar recursos n√£o utilizados
docker system prune -a --volumes

# Verificar logs de erro em todos os servi√ßos
docker-compose logs | grep -i error

# Monitorar logs em tempo real
docker-compose logs -f --tail=100
```

## Casos de Uso Educacionais

### 1. **Data Discovery & Cataloging**
- ‚úÖ Descoberta autom√°tica de esquemas de banco de dados
- ‚úÖ Cataloga√ß√£o de tabelas, colunas e relacionamentos
- ‚úÖ Busca e navega√ß√£o no cat√°logo centralizado
- ‚úÖ Extra√ß√£o de metadados via JDBC
- **Lab**: `catalog_postgres_to_atlas` DAG

### 2. **Metadata Management**
- ‚úÖ Extra√ß√£o de metadados estruturais e t√©cnicos
- ‚úÖ Cria√ß√£o de entidades customizadas no Atlas
- ‚úÖ Relacionamentos entre entidades (foreign keys)
- ‚úÖ Classifica√ß√£o e tagging automatizado
- **Lab**: `Lab_Catalogo_Postgres_no_Atlas.ipynb`

### 3. **Data Lineage & Provenance**
- ‚úÖ Mapeamento completo de origem dos dados
- ‚úÖ Rastreamento de transforma√ß√µes ETL
- ‚úÖ Visualiza√ß√£o gr√°fica de fluxos de dados
- ‚úÖ Linhagem autom√°tica via Spark
- ‚úÖ Processos de ETL registrados no Atlas
- **Lab**: `etl_northwind_to_iceberg` DAG

### 4. **API Integration & Automation**
- ‚úÖ Uso de REST APIs do Apache Atlas
- ‚úÖ Autentica√ß√£o e autoriza√ß√£o
- ‚úÖ Opera√ß√µes CRUD em metadados
- ‚úÖ Integra√ß√£o com Python (requests)
- **Lab**: `lab/atlas_client.py`

### 5. **DataOps & Orchestration**
- ‚úÖ Workflows automatizados com Airflow
- ‚úÖ Pipelines de cataloga√ß√£o cont√≠nua
- ‚úÖ Integra√ß√£o com ferramentas de CI/CD
- ‚úÖ Monitoramento de qualidade de dados
- ‚úÖ Tags de qualidade automatizadas
- **Lab**: Todos os DAGs do Airflow

### 6. **Data Lake & Versioning**
- ‚úÖ Armazenamento em formato Apache Iceberg
- ‚úÖ Versionamento de dados (time travel)
- ‚úÖ Schema evolution
- ‚úÖ ACID transactions
- **Lab**: `Iceberg_Demo.ipynb`

### 7. **Observability & Monitoring**
- ‚úÖ Coleta de logs centralizada
- ‚úÖ M√©tricas de containers em tempo real
- ‚úÖ Dashboards de sa√∫de da plataforma
- ‚úÖ Alertas configur√°veis
- **Lab**: Kibana Dashboards (`monitoring/`)

## Pr√≥ximos Passos - Roadmap

### Evolu√ß√£o para Plataforma DataOps Completa

Os pr√≥ximos desenvolvimentos deste reposit√≥rio incluir√£o a implementa√ß√£o de uma **plataforma DataOps completa** com orquestra√ß√£o avan√ßada e linhagem autom√°tica de dados:

#### **Apache Airflow - Orquestra√ß√£o de ETLs**
- **Scheduler Avan√ßado**: Orquestra√ß√£o de pipelines de dados complexos
- **DAGs Automatizados**: Workflows para descoberta e cataloga√ß√£o cont√≠nua
- **Monitoramento**: Interface web para acompanhamento de execu√ß√µes
- **Integra√ß√£o Atlas**: DAGs espec√≠ficos para sincroniza√ß√£o de metadados

#### **Apache Spark - Engine de Transforma√ß√£o**
- **Processamento Distribu√≠do**: Transforma√ß√µes em larga escala
- **Conectores Nativos**: Integra√ß√£o direta com PostgreSQL e Atlas
- **Spark Streaming**: Processamento de dados em tempo real
- **Delta Lake**: Versionamento e qualidade de dados

#### **Linhagem Autom√°tica de Dados**
- **Rastreamento Completo**: Origem ‚Üí Transforma√ß√£o ‚Üí Destino
- **Spark Lineage**: Captura autom√°tica via Spark Listener
- **Atlas Integration**: Registro autom√°tico de processos ETL
- **Visualiza√ß√£o Gr√°fica**: Mapeamento visual de fluxos de dados

### **Arquitetura Futura**

### **Funcionalidades Implementadas e Planejadas**

| Componente | Funcionalidade | Status | Detalhes |
|------------|----------------|--------|----------|
| **Airflow** | DAGs de cataloga√ß√£o autom√°tica | ‚úÖ **Implementado** | 4 DAGs operacionais |
| **Airflow** | DAG de limpeza do Atlas | ‚úÖ **Implementado** | Manuten√ß√£o completa |
| **Airflow** | DAG ETL Spark + Iceberg | ‚úÖ **Implementado** | Pipeline completo |
| **Airflow** | Submiss√£o remota de Spark Jobs | ‚úÖ **Implementado** | Via Docker socket |
| **Atlas** | Cataloga√ß√£o via API REST | ‚úÖ **Implementado** | CRUD completo |
| **Atlas** | Linhagem autom√°tica de dados | ‚úÖ **Implementado** | End-to-end lineage |
| **Atlas** | Tags de qualidade automatizadas | ‚úÖ **Implementado** | Quality tags |
| **Atlas** | Tipos customizados (rdbms_*) | ‚úÖ **Implementado** | Database, Table, Column |
| **PostgreSQL** | Extra√ß√£o de metadados Northwind | ‚úÖ **Implementado** | 14 tabelas |
| **Spark** | Jobs ETL com Iceberg | ‚úÖ **Implementado** | Distributed processing |
| **Spark** | Integra√ß√£o com Atlas | ‚úÖ **Implementado** | Metadata registration |
| **Iceberg** | Armazenamento com versionamento | ‚úÖ **Implementado** | Time travel |
| **Iceberg** | Schema evolution | ‚úÖ **Implementado** | Dynamic schemas |
| **Monitoring** | Elasticsearch + Kibana | ‚úÖ **Implementado** | Logs centralizados |
| **Monitoring** | Filebeat (Log shipping) | ‚úÖ **Implementado** | Airflow + Docker logs |
| **Monitoring** | Metricbeat (Metrics) | ‚úÖ **Implementado** | Container metrics |
| **Monitoring** | Dashboards pr√©-configurados | ‚úÖ **Implementado** | Health dashboards |
| **Jupyter** | Notebooks interativos | ‚úÖ **Implementado** | 2 labs completos |
| **Governance** | Pol√≠ticas avan√ßadas | üìã **Planejado** | Access control |
| **Governance** | Data Quality Rules | üìã **Planejado** | Automated validation |
| **Integration** | Conectores adicionais | üìã **Planejado** | MySQL, MongoDB, S3 |

### **Benef√≠cios da Evolu√ß√£o**

- **Automa√ß√£o Completa**: Descoberta e cataloga√ß√£o sem interven√ß√£o manual
- **Linhagem End-to-End**: Rastreamento completo do ciclo de vida dos dados
- **Escalabilidade**: Processamento distribu√≠do para grandes volumes
- **Governan√ßa Avan√ßada**: Pol√≠ticas e qualidade automatizadas
- **Observabilidade**: Monitoramento completo de pipelines

### **Como Contribuir**

Interessado em contribuir com essas funcionalidades? √Åreas de desenvolvimento:

- **Airflow DAGs**: Desenvolvimento de workflows de cataloga√ß√£o
- **Spark Jobs**: Implementa√ß√£o de ETLs com captura de linhagem
- **Atlas Hooks**: Conectores customizados para diferentes fontes
- **Monitoring**: Dashboards e alertas de qualidade
- **Documentation**: Tutoriais e guias avan√ßados

## Contribui√ß√£o

Este √© um projeto educacional open-source. Contribui√ß√µes s√£o muito bem-vindas!

### Como Contribuir

1. **Fork** o reposit√≥rio
2. **Clone** seu fork localmente
   ```bash
   git clone https://github.com/seu-usuario/atlas-dataops-lab.git
   ```
3. **Crie** uma branch para sua feature
   ```bash
   git checkout -b feature/minha-feature
   ```
4. **Commit** suas mudan√ßas
   ```bash
   git commit -m "feat: adiciona nova funcionalidade X"
   ```
5. **Push** para a branch
   ```bash
   git push origin feature/minha-feature
   ```
6. **Abra** um Pull Request no GitHub

### √Åreas de Contribui√ß√£o

#### Conectores de Dados
- [ ] Conector para MySQL
- [ ] Conector para MongoDB
- [ ] Conector para AWS S3
- [ ] Conector para Azure Data Lake
- [ ] Conector para Google BigQuery

#### Intelig√™ncia e Automa√ß√£o
- [ ] Classifica√ß√£o autom√°tica de dados sens√≠veis (PII)
- [ ] Detec√ß√£o de anomalias em metadados
- [ ] Sugest√µes de relacionamentos baseadas em ML
- [ ] An√°lise de qualidade de dados automatizada

#### Visualiza√ß√£o e BI
- [ ] Integra√ß√£o com Apache Superset
- [ ] Integra√ß√£o com Metabase
- [ ] Dashboards customizados no Kibana
- [ ] Relat√≥rios de governan√ßa automatizados

#### Testes e Qualidade
- [ ] Testes unit√°rios para DAGs
- [ ] Testes de integra√ß√£o
- [ ] Testes de performance
- [ ] CI/CD com GitHub Actions

#### Documenta√ß√£o
- [ ] Tutoriais em v√≠deo
- [ ] Guias avan√ßados
- [ ] Tradu√ß√µes (EN, ES)
- [ ] Exemplos de casos de uso reais

#### Seguran√ßa e Governan√ßa
- [ ] Autentica√ß√£o LDAP/AD
- [ ] Controle de acesso granular
- [ ] Auditoria de opera√ß√µes
- [ ] Criptografia de dados sens√≠veis

### Diretrizes de C√≥digo

- Siga o estilo PEP 8 para Python
- Adicione docstrings em fun√ß√µes e classes
- Inclua testes para novas funcionalidades
- Atualize a documenta√ß√£o relevante
- Use commits sem√¢nticos (feat, fix, docs, etc.)

### Reportar Bugs

Encontrou um bug? Abra uma issue com:
- Descri√ß√£o clara do problema
- Passos para reproduzir
- Comportamento esperado vs atual
- Logs relevantes
- Vers√£o do Docker e sistema operacional

## Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para detalhes.

## Estat√≠sticas do Projeto

- **Containers**: 8 servi√ßos orquestrados
- **DAGs**: 4 workflows automatizados
- **Notebooks**: 2 laborat√≥rios interativos
- **Tabelas**: 14 tabelas Northwind catalogadas
- **Metadados**: ~200 entidades no Atlas
- **Linhagem**: Pipeline completo PostgreSQL ‚Üí Iceberg
- **Monitoramento**: Logs e m√©tricas em tempo real

## Suporte e Comunidade

- **Issues**: [GitHub Issues](https://github.com/AleTavares/atlas-dataops-lab/issues)
- **Discussions**: [GitHub Discussions](https://github.com/AleTavares/atlas-dataops-lab/discussions)
- **Email**: Abra uma issue para contato

## Agradecimentos

- **Apache Atlas Community** - Pela excelente ferramenta de governan√ßa de dados
- **Apache Airflow** - Pela plataforma de orquestra√ß√£o robusta
- **Apache Spark** - Pelo engine de processamento distribu√≠do
- **Apache Iceberg** - Pelo formato de tabela com versionamento
- **Elastic Stack** - Pela stack completa de observabilidade
- **Northwind Database** - Pelo dataset educacional cl√°ssico
- **Docker Community** - Pela containeriza√ß√£o simplificada
- **Jupyter Project** - Pelo ambiente interativo de an√°lise

## Cita√ß√£o

Se voc√™ usar este projeto em pesquisa ou ensino, por favor cite:

```bibtex
@software{atlas_dataops_lab,
  author = {Alexandre Tavares},
  title = {Apache Atlas DataOps Lab},
  year = {2025},
  url = {https://github.com/AleTavares/atlas-dataops-lab},
  description = {Plataforma completa de aprendizado para Data Governance e DataOps}
}
```

**Para come√ßar, acesse os laborat√≥rios em ordem:**
1. [Lab Python B√°sico](lab/LAB_ATLAS_PYTHON.md)
2. [Exerc√≠cio Pr√°tico](Exercicios/EXERCICIO_ATLAS.md)
3. [Notebook Interativo](notebooks/Lab_Catalogo_Postgres_no_Atlas.ipynb)